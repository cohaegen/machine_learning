{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Pre-trained Transformer (GPT) in Tensorflow\n",
    "\n",
    "This is a fun experiment in GPTs inspired by Andrej Karpathy: https://www.youtube.com/watch?v=kCc8FmEb1nY. He's a great teacher and has taught classes, written about ML, and posted videos about ML for years.\n",
    "\n",
    "Karpathy walks through writing a GPT from scratch using the mini-Shakespeare dataset and PyTorch. I'm more used to TensorFlow, so I wanted to try and follow along using TF. I didn't quite write this from scratch; Andrej implements a multi-head attention layer from scratch, but TensorFlow includes a MultiHeadAttention layer so I used that. It's worth paying attention in Andrej's tutorial to see what's going on in an attention layer though; the key, value, and query concepts are useful to understand.\n",
    "\n",
    "I also wanted to try more data, so I used the complete works of William Shakespeare instead of the mini-Shakespeare dataset.\n",
    "\n",
    "I put a slight spin on the training/inference approach by creating \"training\" and \"production\" models. The training model requires tokens as input. The tokens have been translated from the raw input bytes. As output, it generates logits for each of the possible tokens that it thinks will come next. The production model takes characters in and spits characters out. It does this by adding an encoding and decoding layer to the inference model after training. Encoding translates the raw bytes into a smaller vocabulary of tokens using a tf.keras.layers.StringLookup layer. On the output, it chooses a next token given the logits and then decodes back to characters. I think this makes it a little easier to pass in data: all you need to do on the input side is split up a string into characters and truncate or pad to the right length, and on the output side, you get characters right out of the model.\n",
    "\n",
    "The original paper on Transformers (\"Attention is All You Need\", Vaswani et al.) is worth a read: https://arxiv.org/pdf/1706.03762.pdf. This implements just the \"decoder\" portion on the right. The decoder predicts the next character in a sequence given a string of recent characters (e.g. given \"To be or not \", it might fill in \"t\", \"o\", \" \", \"b\", \"e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implementation of a Generative Pre-Trained Transformer (GPT) in Tensorflow\n",
    "\"\"\"\n",
    "import os\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Define some constants\n",
    "INPUT_FILE = 't8.shakespeare.txt'\n",
    "# FILE_URL = 'https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt'\n",
    "FILE_URL = 'http://localhost:8000/t8.shakespeare.txt'\n",
    "TIMESERIES_CONTEXT = 32  # how many characters to use for prediction?\n",
    "BATCH_SIZE = 32\n",
    "NUM_HEADS = 4  # Number of attention heads in each layer\n",
    "HEAD_SIZE = 32  # Number of units in each head\n",
    "DROPOUT = 0.2  # Dropout regularization in the attention and dense layers\n",
    "NUM_LAYERS = 6  # Number of attention layers\n",
    "LEARNING_RATE = 3e-4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformers need some sort of information that associates each input with its position. I'm doing that here with just a range of integers fed into an embedding layer. That gets added to an embedding layer that represents the input characters themselves. This layer class implements both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, context_size, embed_size):\n",
    "        super().__init__()\n",
    "        self.pos_embedding = tf.keras.layers.Embedding(vocab_size, embed_size)\n",
    "        self.tok_embedding = tf.keras.layers.Embedding(context_size, embed_size)\n",
    "        self.positions = tf.range(0, context_size)\n",
    "    \n",
    "    def call(self, values):\n",
    "        return self.pos_embedding(values) + self.tok_embedding(self.positions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the actual Transformer Decoder layer. This is based on the Attention Is All You Need paper but with the layer normalization performed before attention and feed-forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_heads: int, head_size: int, dropout: int):\n",
    "        super().__init__()\n",
    "        self.attention = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=head_size, dropout=dropout)\n",
    "        # The feed-forward layer includes a multiple of the input size in a non-linear multi-layer perceptron as a calculation stage,\n",
    "        # followed by a linear layer that maps the dimensions back to the input size\n",
    "        self.feed_forward = tf.keras.Sequential([tf.keras.layers.Dense(4*num_heads*head_size, activation='gelu'),\n",
    "                                                 tf.keras.layers.Dense(num_heads*head_size),\n",
    "                                                 tf.keras.layers.Dropout(dropout)])\n",
    "        self.layer_norm1 = tf.keras.layers.LayerNormalization()\n",
    "        self.layer_norm2 = tf.keras.layers.LayerNormalization()\n",
    "    \n",
    "    def call(self, values):\n",
    "        norm_values = self.layer_norm1(values)\n",
    "        # At both the attention and feed-forward layers, we include a residual (values and attn) that helps accelerate convergence\n",
    "        attn = values + self.attention(norm_values, norm_values, attention_mask=np.tri(TIMESERIES_CONTEXT))\n",
    "        norm_attn = self.layer_norm2(attn)\n",
    "        feed_fwd = attn + self.feed_forward(norm_attn)\n",
    "        # The output shape is going to be the same as the input shape\n",
    "        return feed_fwd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add some utility functions for reading data and generating random slices for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input(input_filename: str):\n",
    "    \"\"\"Read the input file and return the encoded dataset and an encoding layer\"\"\"\n",
    "    raw_input = list(open(input_filename).read())\n",
    "    vocabulary = sorted(list(set(raw_input)))\n",
    "    encoder = tf.keras.layers.StringLookup(vocabulary=vocabulary)\n",
    "    enc_input = encoder(raw_input).numpy()\n",
    "    return enc_input, encoder\n",
    "\n",
    "\n",
    "def generate_batches(data: np.array, context_size, batch_size):\n",
    "    \"\"\"Generate batches of value,target pairs for training\"\"\"\n",
    "    # Create shuffled starting offsets into the data\n",
    "    starting_offsets = np.arange(len(data)-context_size)\n",
    "    np.random.shuffle(starting_offsets)\n",
    "    for batch_idx in range(0, len(starting_offsets), batch_size):\n",
    "        batch_starting_offsets = starting_offsets[batch_idx:(batch_idx+batch_size)].reshape((-1,1))\n",
    "        # Turn the starting offsets into indices: this will project the arange across all of the \n",
    "        # starting_offsets so something like [[5], [11], [3]] becomes [[5, 6, 7], [11, 12, 13], [3, 4, 5]]\n",
    "        indices = batch_starting_offsets + np.arange(context_size)\n",
    "        values = data[indices]\n",
    "        # The targets (what we want to predict) are just the next characters\n",
    "        targets = data[indices+1]\n",
    "        yield values, targets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(encoder):\n",
    "    \"\"\"Create the GPT model and return it\"\"\"\n",
    "    # At each layer, I'll show the output dimensions. B means the batch dimension, T means the time dimension (characters), and C is the channel dimension (number of different values for each character)\n",
    "    values_input = tf.keras.layers.Input(shape=(TIMESERIES_CONTEXT,), name='values_input')  # (B, T)\n",
    "    layer = TokenAndPositionEmbedding(encoder.vocabulary_size(), TIMESERIES_CONTEXT, NUM_HEADS*HEAD_SIZE)(values_input)  # (B, T, NUM_HEADS*HEAD_SIZE)\n",
    "    for _ in range(NUM_LAYERS):\n",
    "        layer = TransformerDecoder(NUM_HEADS, HEAD_SIZE, DROPOUT)(layer)  # (B, T, NUM_HEADS*HEAD_SIZE)\n",
    "    # One last layer normalization\n",
    "    layer = tf.keras.layers.LayerNormalization()(layer)  # (B, T, NUM_HEADS*HEAD_SIZE)\n",
    "    # And map to the vocabulary size\n",
    "    output = tf.keras.layers.Dense(encoder.vocabulary_size())(layer)  # (B, T, C)\n",
    "\n",
    "    model = tf.keras.Model(inputs=values_input, outputs=output)\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)  # This loss lets us pass in integers rather than having to one-hot encode\n",
    "    optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put all the pieces together: create the model, train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-30 10:05:01.928704: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2023-07-30 10:05:01.928734: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2023-07-30 10:05:01.928739: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2023-07-30 10:05:01.928765: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-07-30 10:05:01.928778: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " values_input (InputLayer)   [(None, 32)]              0         \n",
      "                                                                 \n",
      " token_and_position_embeddi  (None, 32, 128)           15872     \n",
      " ng (TokenAndPositionEmbedd                                      \n",
      " ing)                                                            \n",
      "                                                                 \n",
      " transformer_decoder (Trans  (None, 32, 128)           198272    \n",
      " formerDecoder)                                                  \n",
      "                                                                 \n",
      " transformer_decoder_1 (Tra  (None, 32, 128)           198272    \n",
      " nsformerDecoder)                                                \n",
      "                                                                 \n",
      " transformer_decoder_2 (Tra  (None, 32, 128)           198272    \n",
      " nsformerDecoder)                                                \n",
      "                                                                 \n",
      " transformer_decoder_3 (Tra  (None, 32, 128)           198272    \n",
      " nsformerDecoder)                                                \n",
      "                                                                 \n",
      " transformer_decoder_4 (Tra  (None, 32, 128)           198272    \n",
      " nsformerDecoder)                                                \n",
      "                                                                 \n",
      " transformer_decoder_5 (Tra  (None, 32, 128)           198272    \n",
      " nsformerDecoder)                                                \n",
      "                                                                 \n",
      " layer_normalization_12 (La  (None, 32, 128)           256       \n",
      " yerNormalization)                                               \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 32, 92)            11868     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1217628 (4.64 MB)\n",
      "Trainable params: 1217628 (4.64 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-30 10:05:14.410849: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 170568/Unknown - 26340s 154ms/step - loss: 1.3683"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-30 17:24:13.362451: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 14427151888607609466\n",
      "2023-07-30 17:24:13.362951: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 7662825767627818096\n",
      "2023-07-30 17:24:13.362955: I tensorflow/core/framework/local_rendezvous.cc:409] Local rendezvous send item cancelled. Key hash: 4727600636621391106\n",
      "2023-07-30 17:24:13.362962: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 14301856541271672186\n",
      "2023-07-30 17:24:13.362966: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 4885685330979769634\n",
      "2023-07-30 17:24:13.362968: I tensorflow/core/framework/local_rendezvous.cc:409] Local rendezvous send item cancelled. Key hash: 17894700199796706868\n",
      "2023-07-30 17:24:13.362972: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 17250457844242042444\n",
      "2023-07-30 17:24:13.362980: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 18007559153044345072\n",
      "2023-07-30 17:24:13.362984: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 11362738464657215792\n",
      "2023-07-30 17:24:13.362987: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 8245340599753572510\n",
      "2023-07-30 17:24:13.363000: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 13602149990502672866\n",
      "2023-07-30 17:24:13.363005: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 9586172249824385374\n",
      "2023-07-30 17:24:13.363010: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 18296954632017072756\n",
      "2023-07-30 17:24:13.363021: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 9547226077277688714\n",
      "2023-07-30 17:24:13.363026: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 6141906894947325098\n",
      "2023-07-30 17:24:13.363029: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 3661606692704835066\n",
      "2023-07-30 17:24:13.363032: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 6404598940826670746\n",
      "2023-07-30 17:24:13.363036: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 13107454998378122594\n",
      "2023-07-30 17:24:13.363047: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 2532824116898217686\n",
      "2023-07-30 17:24:13.363051: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 16033295037056341972\n",
      "2023-07-30 17:24:13.363054: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 4703511124407058597\n",
      "2023-07-30 17:24:13.363059: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 13569969870222349494\n",
      "2023-07-30 17:24:13.363065: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 6401212890880114753\n",
      "2023-07-30 17:24:13.363067: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 10025048853994772976\n",
      "2023-07-30 17:24:13.363069: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 15953689269178729907\n",
      "2023-07-30 17:24:13.363071: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 6572947434253507134\n",
      "2023-07-30 17:24:13.363073: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 4055209993213920841\n",
      "2023-07-30 17:24:13.363077: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 1082950187225439036\n",
      "2023-07-30 17:24:13.363081: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 1048715848533772423\n",
      "2023-07-30 17:24:13.363086: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 6362840798340095020\n",
      "2023-07-30 17:24:13.363089: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 1793264024870635751\n",
      "2023-07-30 17:24:13.363094: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 9128964581580431044\n",
      "2023-07-30 17:24:13.363097: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 13428083878950881983\n",
      "2023-07-30 17:24:13.363102: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 18298085149625622242\n",
      "2023-07-30 17:24:13.363106: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 4482271995565395425\n",
      "2023-07-30 17:24:13.363110: I tensorflow/core/framework/local_rendezvous.cc:409] Local rendezvous send item cancelled. Key hash: 9048122261002817073\n",
      "2023-07-30 17:24:13.363114: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 868553445569367867\n",
      "2023-07-30 17:24:13.363117: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 17598720643216904473\n",
      "2023-07-30 17:24:13.363121: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 403443424931877321\n",
      "2023-07-30 17:24:13.363125: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 14656942534389142059\n",
      "2023-07-30 17:24:13.363131: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 9934752978014917781\n",
      "2023-07-30 17:24:13.363134: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 10297506427490227891\n",
      "2023-07-30 17:24:13.363137: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 10602358982349346959\n",
      "2023-07-30 17:24:13.363140: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 7455280433953692325\n",
      "2023-07-30 17:24:13.363144: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 11067380048267615997\n",
      "2023-07-30 17:24:13.363148: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 9640364113650098394\n",
      "2023-07-30 17:24:13.363154: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 7266381135752995019\n",
      "2023-07-30 17:24:13.363156: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 13368861460037673446\n",
      "2023-07-30 17:24:13.363158: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 13558900392129569413\n",
      "2023-07-30 17:24:13.363162: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 13676024189009600754\n",
      "2023-07-30 17:24:13.363167: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 514800092727387166\n",
      "2023-07-30 17:24:13.363171: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 7527236098144118353\n",
      "2023-07-30 17:24:13.363178: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 12690012526988716159\n",
      "2023-07-30 17:24:13.363182: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 6946030050175773147\n",
      "2023-07-30 17:24:13.363185: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 17061995754360531499\n",
      "2023-07-30 17:24:13.363189: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 15267734153201462663\n",
      "2023-07-30 17:24:13.363192: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 18158589012872506985\n",
      "2023-07-30 17:24:13.363195: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 13630988736755625613\n",
      "2023-07-30 17:24:13.363198: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 9051773873853706297\n",
      "2023-07-30 17:24:13.363201: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 14596226957807658054\n",
      "2023-07-30 17:24:13.363209: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 14456913969365149406\n",
      "2023-07-30 17:24:13.363213: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 3801198765784247838\n",
      "2023-07-30 17:24:13.363219: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 7902165678800056088\n",
      "2023-07-30 17:24:13.363222: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 10643711012809748647\n",
      "2023-07-30 17:24:13.363228: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 16294735113805328218\n",
      "2023-07-30 17:24:13.363232: I tensorflow/core/framework/local_rendezvous.cc:409] Local rendezvous send item cancelled. Key hash: 6713995601892142762\n",
      "2023-07-30 17:24:13.363237: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 15930386864737662291\n",
      "2023-07-30 17:24:13.363241: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 309336944902795680\n",
      "2023-07-30 17:24:13.363245: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 8321852998861419783\n",
      "2023-07-30 17:24:13.363249: I tensorflow/core/framework/local_rendezvous.cc:409] Local rendezvous send item cancelled. Key hash: 6256448654892054307\n",
      "2023-07-30 17:24:13.363253: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 11897398938764622291\n",
      "2023-07-30 17:24:13.363256: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 4872316753459411649\n",
      "2023-07-30 17:24:13.363260: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 865952610009791099\n",
      "2023-07-30 17:24:13.363263: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 8824437565169908127\n",
      "2023-07-30 17:24:13.363266: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 9628081258389159411\n",
      "2023-07-30 17:24:13.363269: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 16053970666344150368\n",
      "2023-07-30 17:24:13.363276: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 733365093325551592\n",
      "2023-07-30 17:24:13.363280: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 10682299737784269000\n",
      "2023-07-30 17:24:13.363283: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 13840344273040259358\n",
      "2023-07-30 17:24:13.363290: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 5518103008636778440\n",
      "2023-07-30 17:24:13.363294: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 17043220266140941448\n",
      "2023-07-30 17:24:13.363297: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 2597763091003407890\n",
      "2023-07-30 17:24:13.363310: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 12084937058004434779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170568/170568 [==============================] - 26341s 154ms/step - loss: 1.3683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x17a7dda80>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the input file if it doesn't exist already\n",
    "if os.path.exists(INPUT_FILE) is False:\n",
    "    with open(INPUT_FILE, 'wb') as outfile:\n",
    "        resp = requests.get(FILE_URL)\n",
    "        outfile.write(resp.content)\n",
    "\n",
    "data, encoder = read_input(INPUT_FILE)\n",
    "model = create_model(encoder)\n",
    "model.summary()\n",
    "# Loss should get down to about 1.3-1.4\n",
    "# You can pass steps_per_epoch to limit the training to fewer batches. You can get some interesting\n",
    "# results at 5,000 and it takes a lot less time (loss about 1.9). The whole file is about 170k.\n",
    "model.fit(generate_batches(data, TIMESERIES_CONTEXT, BATCH_SIZE))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a production model that has a character encoder layer on the input, and a decoder layer on the output that translates logits back into characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InverseLookupLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, encoder: tf.keras.layers.StringLookup):\n",
    "        super().__init__()\n",
    "        self.decoder = tf.keras.layers.StringLookup(vocabulary=encoder.get_vocabulary(), invert=True)\n",
    "    \n",
    "    def call(self, logits):\n",
    "        # Pick the last character prediction in each batch row\n",
    "        # Then, for each batch row, choose a character based on the logit probabilities\n",
    "        choose_chars = tf.random.categorical(logits[:,-1,:], num_samples=1)\n",
    "        # Decode back to characters\n",
    "        return self.decoder(choose_chars)\n",
    "\n",
    "\n",
    "def create_production_model(model, encoder):\n",
    "    \"\"\"Add a character encoder and decoder layer at the front and back of the model\"\"\"\n",
    "    chars_input = tf.keras.layers.Input(shape=(TIMESERIES_CONTEXT,), dtype=tf.string)\n",
    "    # Strip the input layer off the training model and add our input with an encoder instead\n",
    "    prod_model = tf.keras.Sequential([chars_input,\n",
    "                                      encoder] +\n",
    "                                      model.layers[1:] +\n",
    "                                      [InverseLookupLayer(encoder)])\n",
    "    return prod_model\n",
    "\n",
    "\n",
    "def generate_text(model: tf.keras.Model, context: str, num_chars: int):\n",
    "    print(context, end='')\n",
    "    for _ in range(num_chars):\n",
    "        context = context[-TIMESERIES_CONTEXT:]  # truncate\n",
    "        context = ['[UNK]'] * (TIMESERIES_CONTEXT - len(context)) + list(context)  # pad with \"unknown\" strings at the front\n",
    "        char = model.predict([context], verbose=0)[0,0].decode()\n",
    "        print(char, end='', flush=True)\n",
    "        context += char"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put everything together and generate some text!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-30 17:24:14.889301: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I OM\n",
      "  GlOOCCONSTAFF\n",
      "  ESCALUS, in a power of beauty, the wax,\n",
      "    who comes here pursues and good fairies your mothers I am clouds recounts,\n",
      "   Talk of Antianus, remain thee be the Garter. I perceive thy mother's tomb,\n",
      "    Here is no more than you blunt;\n",
      "    Tears with our cold fathers; your returns a peril\n",
      "    Did to prove ill this kingdom?\n",
      "  Pedro. At my presence, ho, have you're\n",
      "    To honest Master Ambassador stay into come to case.\n",
      "    Look, my lord, that's potent, there anything,\n",
      "    How now, though thou say'st me fought at the subject. One for a porbation\n",
      "    COMINIUS OF EPHESUS, Duke of Signior\n",
      "\n",
      "Enter SIR TOBY, and PISANIO and other ThIsby\n",
      "    Here came I in thine own lord that taste be than I\n",
      "    beseech your mother must make speed a little wanting set,\n",
      "  When nor time to draw thee there would lay prisoners come off,\n",
      "    And be fruitful.\n",
      "  PEY. Hear what preciously shift thy company can I each love and life\n",
      "    Zetbear this deed liveries, and cry and denatory,\n",
      "   His rifts ha"
     ]
    }
   ],
   "source": [
    "prod_model = create_production_model(model, encoder)\n",
    "generate_text(prod_model, context='   A', num_chars=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
